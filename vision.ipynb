{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mss\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "VID_OUTPUT_DIR = 'video_out'        # Directory to save video output\n",
    "LABEL = False                       # Whether or not to label during capture process      \n",
    "FPS = 1                             # Frames to capture per second\n",
    "SECONDS_TO_CAPTURE = 60             # Video duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda NVIDIA GeForce RTX 3050 Ti Laptop GPU with 3090.4500007629395 MB of VRAM\n"
     ]
    }
   ],
   "source": [
    "if DEVICE == torch.device('cuda'):\n",
    "    print(f'Using {DEVICE} {torch.cuda.get_device_name()} with {torch.cuda.mem_get_info()[0]/(1024**2)} MB of VRAM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('yolov5'):\n",
    "  !git clone https://github.com/ultralytics/yolov5\n",
    "  !pip install -r yolov5/requirements.txt\n",
    "  \n",
    "\n",
    "if not os.path.exists(VID_OUTPUT_DIR):\n",
    "  os.makedirs(VID_OUTPUT_DIR)\n",
    "  \n",
    "warnings.simplefilter(\"ignore\", FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'left': 0, 'top': 0, 'width': 3840, 'height': 1080}, {'left': 1920, 'top': 0, 'width': 1920, 'height': 1080}, {'left': 0, 'top': 0, 'width': 1920, 'height': 1080}]\n"
     ]
    }
   ],
   "source": [
    "with mss.mss() as sct:\n",
    "  print(sct.monitors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger('ultralytics').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\tiany/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2024-10-19 Python-3.10.6 torch-2.4.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients, 4.5 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitor: {'left': 1920, 'top': 0, 'width': 1920, 'height': 1080}\n",
      "Capturing regions: {'left': 2568, 'top': 0, 'width': 628, 'height': 1080} and {'left': 3206, 'top': 0, 'width': 39, 'height': 724}\n",
      "Capture region 1 saved to video_out/output_1.mp4\n",
      "Capture region 2 saved to video_out/output_2.mp4\n"
     ]
    }
   ],
   "source": [
    "frames_to_capture = FPS * SECONDS_TO_CAPTURE\n",
    "frames = []\n",
    "# yolov5 = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "# yolov5.eval()\n",
    "\n",
    "yolov5 = torch.hub.load('ultralytics/yolov5', 'yolov5n', pretrained=True)\n",
    "yolov5.eval()\n",
    "\n",
    "def detect(img, model):\n",
    "  img = model(img)\n",
    "  \n",
    "  return img.render()[0]\n",
    "\n",
    "def capture(region):\n",
    "  with mss.mss() as sct:\n",
    "    return sct.grab(region)\n",
    "\n",
    "monitor_1 = mss.mss().monitors[1]\n",
    "print(f'Monitor: {monitor_1}')\n",
    "t, l, w, h = monitor_1['top'], monitor_1['left'], monitor_1['width'], monitor_1['height']\n",
    "region_1 = {'left': l+int(w * 0.338), 'top': t, 'width': w-int(w * 0.673), 'height': h}\n",
    "region_2 = {'left': l+int(w * 0.67), 'top': t, 'width': w-int(w * 0.98), 'height': h-int(h * 0.33)}\n",
    "# region_2 = {'left': l+int(l * 0.859), 'top': t, 'width': w-int(w * 0.820), 'height': h-int(h * 0.952)}\n",
    "\n",
    "print(f'Capturing regions: {region_1} and {region_2}')\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out_1 = cv2.VideoWriter(f'{VID_OUTPUT_DIR}/output_1.mp4', fourcc, FPS, (region_1['width'], region_1['height']))\n",
    "out_2 = cv2.VideoWriter(f'{VID_OUTPUT_DIR}/output_2.mp4', fourcc, FPS, (region_2['width'], region_2['height']))\n",
    "model = yolov5\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "  for i in range(frames_to_capture):\n",
    "    time_start = time.time()\n",
    "    thread_1 = executor.submit(capture, region_1)\n",
    "    thread_2 = executor.submit(capture, region_2)\n",
    "    \n",
    "    img_1 = thread_1.result()\n",
    "    img_2 = thread_2.result()\n",
    "    \n",
    "    if LABEL:\n",
    "      # img_1 = cv2.resize(np_img_1, (int(np_img_1.shape[0] * 0.5), int(np_img_1.shape[1] * 0.5)))\n",
    "      # img_2 = cv2.resize(np_img_2, (int(np_img_2.shape[0] * 0.5), int(np_img_2.shape[1] * 0.5)))\n",
    "\n",
    "      thread_1 = executor.submit(detect, np.array(img_1), model)\n",
    "      thread_2 = executor.submit(detect, np.array(img_2), model)\n",
    "\n",
    "      img_1 = thread_1.result()\n",
    "      img_2 = thread_2.result()\n",
    "    \n",
    "    out_1.write(cv2.cvtColor(np.array(img_1), cv2.COLOR_BGRA2BGR))\n",
    "    out_2.write(cv2.cvtColor(np.array(img_2), cv2.COLOR_BGRA2BGR))\n",
    "    \n",
    "    if time_start + 1/FPS > time.time():\n",
    "      time.sleep(time_start + 1/FPS - time.time())\n",
    "\n",
    "out_1.release()\n",
    "out_2.release()\n",
    "print(f'Capture region 1 saved to {VID_OUTPUT_DIR}/output_1.mp4')\n",
    "print(f'Capture region 2 saved to {VID_OUTPUT_DIR}/output_2.mp4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
