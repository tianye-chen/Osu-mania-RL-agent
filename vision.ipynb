{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mss\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "VID_OUTPUT_DIR = 'video_out'        # Directory to save video output\n",
    "DETECT = True                       # Whether or not to label during capture process, False to simply record and output videos. No output if true\n",
    "FPS = 15                            # Frames to capture per second\n",
    "SECONDS_TO_CAPTURE = 60             # Video duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda NVIDIA GeForce RTX 3050 Ti Laptop GPU with 3144.4500007629395 MB of VRAM\n"
     ]
    }
   ],
   "source": [
    "if DEVICE == torch.device('cuda'):\n",
    "    print(f'Using {DEVICE} {torch.cuda.get_device_name()} with {torch.cuda.mem_get_info()[0]/(1024**2)} MB of VRAM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('yolov5'):\n",
    "  !git clone https://github.com/ultralytics/yolov5\n",
    "  !pip install -r yolov5/requirements.txt\n",
    "  \n",
    "\n",
    "if not os.path.exists(VID_OUTPUT_DIR):\n",
    "  os.makedirs(VID_OUTPUT_DIR)\n",
    "  \n",
    "warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "logging.getLogger('ultralytics').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to C:\\Users\\tiany/.cache\\torch\\hub\\master.zip\n",
      "YOLOv5  2024-10-30 Python-3.10.6 torch-2.4.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "pathlib.PosixPath = pathlib.WindowsPath # https://github.com/ultralytics/yolov5/issues/10240#issuecomment-1662573188\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='./models/best.pt', force_reload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(img, model):\n",
    "  lanes = {\n",
    "    0 : (10, 180),\n",
    "    1 : (150, 320),\n",
    "    2 : (300, 470),\n",
    "    3 : (440, 610)\n",
    "  }\n",
    "  ret = []  \n",
    "  res = model(img)\n",
    "  \n",
    "  for box in res.xyxy[0]:\n",
    "    x_center = int((box[0] + box[2]) / 2)\n",
    "    y_center = int((box[1] + box[3]) / 2)\n",
    "    \n",
    "    for lane, (start, end) in lanes.items():\n",
    "      if start <= x_center <= end:\n",
    "        break\n",
    "    \n",
    "    ret.append([lane, y_center])\n",
    "  \n",
    "  return ret \n",
    "\n",
    "def capture(region):\n",
    "  with mss.mss() as sct:\n",
    "    return sct.grab(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitor: {'left': 1920, 'top': 0, 'width': 1920, 'height': 1080}\n",
      "Capturing {'left': 2568, 'top': 0, 'width': 628, 'height': 1080}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[116], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m# If the current loop finishes faster than the FPS, wait.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time_start \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mFPS \u001b[38;5;241m>\u001b[39m time\u001b[38;5;241m.\u001b[39mtime():\n\u001b[1;32m---> 31\u001b[0m       \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mFPS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m DETECT:\n\u001b[0;32m     34\u001b[0m   out_1\u001b[38;5;241m.\u001b[39mrelease()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "frames_to_capture = FPS * SECONDS_TO_CAPTURE\n",
    "frames = []\n",
    "\n",
    "monitor_1 = mss.mss().monitors[1]\n",
    "print(f'Monitor: {monitor_1}')\n",
    "t, l, w, h = monitor_1['top'], monitor_1['left'], monitor_1['width'], monitor_1['height']\n",
    "region_1 = {'left': l+int(w * 0.338), 'top': t, 'width': w-int(w * 0.673), 'height': h} # Gameplay region\n",
    "# region_2 = {'left': l+int(w * 0.67), 'top': t, 'width': w-int(w * 0.98), 'height': h-int(h * 0.33)} # Judgement counter region\n",
    "# region_3 = {'left': l+int(l * 0.859), 'top': t, 'width': w-int(w * 0.820), 'height': h-int(h * 0.952)} # Score region\n",
    "\n",
    "print(f'Capturing {region_1}')\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out_1 = cv2.VideoWriter(f'{VID_OUTPUT_DIR}/output_1.mp4', fourcc, FPS, (region_1['width'], region_1['height']))\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "  for i in range(frames_to_capture):\n",
    "    time_start = time.time()\n",
    "    thread_1 = executor.submit(capture, region_1)\n",
    "    img_1 = thread_1.result()\n",
    "    \n",
    "    if DETECT:\n",
    "      thread_1 = executor.submit(detect, np.array(img_1), model)\n",
    "      notes = thread_1.result() # Outputs notes in [[lane_num, y_center_pos]...]\n",
    "      print(notes)\n",
    "    else:\n",
    "      out_1.write(cv2.cvtColor(np.array(img_1), cv2.COLOR_BGRA2BGR))\n",
    "    \n",
    "    # If the current loop finishes faster than the FPS, wait.\n",
    "    if time_start + 1/FPS > time.time():\n",
    "      time.sleep(time_start + 1/FPS - time.time())\n",
    "\n",
    "if not DETECT:\n",
    "  out_1.release()\n",
    "  print(f'Capture region saved to {VID_OUTPUT_DIR}/output_1.mp4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
